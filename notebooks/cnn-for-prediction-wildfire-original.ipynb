{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2824184,"sourceType":"datasetVersion","datasetId":1726926}],"dockerImageVersionId":30145,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load libraries","metadata":{"id":"uPojRlNQPJub"}},{"cell_type":"markdown","source":"Import the required libraries.","metadata":{"id":"oOtnY2y8Om-1"}},{"cell_type":"code","source":"import re\nfrom typing import Dict, List, Optional, Text, Tuple\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nimport tensorflow as tf\nimport numpy as np\n\n\nfrom tqdm import tqdm\nfrom typing import Callable, Tuple\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.keras.utils.losses_utils import reduce_weighted_loss","metadata":{"id":"1Mf4kbp8yOxd","execution":{"iopub.status.busy":"2024-04-19T20:47:27.814529Z","iopub.execute_input":"2024-04-19T20:47:27.815337Z","iopub.status.idle":"2024-04-19T20:47:27.821956Z","shell.execute_reply.started":"2024-04-19T20:47:27.815293Z","shell.execute_reply":"2024-04-19T20:47:27.821163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data","metadata":{"id":"aVb2hhOcgVwU"}},{"cell_type":"markdown","source":"Run the following three cells to define the required library functions for loading the data.\n\nThe first cell defines the name of the variables in the input files and the corrresponding data statistics. The statistics can be used for preprocessing the data. ","metadata":{"id":"OabUJMGqO9NE"}},{"cell_type":"code","source":"\"\"\"Constants for the data reader.\"\"\"\n\nINPUT_FEATURES = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph', \n                  'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask']\n\nOUTPUT_FEATURES = ['FireMask', ]\n\n# Data statistics \n# For each variable, the statistics are ordered in the form:\n# (min_clip, max_clip, mean, standard deviation)\nDATA_STATS = {\n    # Elevation in m.\n    # 0.1 percentile, 99.9 percentile\n    'elevation': (0.0, 3141.0, 657.3003, 649.0147),\n    # Pressure\n    # 0.1 percentile, 99.9 percentile\n    'pdsi': (-6.12974870967865, 7.876040384292651, -0.0052714925, 2.6823447),\n    'NDVI': (-9821.0, 9996.0, 5157.625, 2466.6677),  # min, max\n    # Precipitation in mm.\n    # Negative values do not make sense, so min is set to 0.\n    # 0., 99.9 percentile\n    'pr': (0.0, 44.53038024902344, 1.7398051, 4.482833),\n    # Specific humidity.\n    # Negative values do not make sense, so min is set to 0.\n    # The range of specific humidity is up to 100% so max is 1.\n    'sph': (0., 1., 0.0071658953, 0.0042835088),\n    # Wind direction in degrees clockwise from north.\n    # Thus min set to 0 and max set to 360.\n    'th': (0., 360.0, 190.32976, 72.59854),\n    # Min/max temperature in Kelvin.\n    # -20 degree C, 99.9 percentile\n    'tmmn': (253.15, 298.94891357421875, 281.08768, 8.982386),\n    # -20 degree C, 99.9 percentile\n    'tmmx': (253.15, 315.09228515625, 295.17383, 9.815496),\n    # Wind speed in m/s.\n    # Negative values do not make sense, given there is a wind direction.\n    # 0., 99.9 percentile\n    'vs': (0.0, 10.024310074806237, 3.8500874, 1.4109988),\n    # NFDRS fire danger index energy release component expressed in BTU's per\n    # square foot.\n    # Negative values do not make sense. Thus min set to zero.\n    # 0., 99.9 percentile\n    'erc': (0.0, 106.24891662597656, 37.326267, 20.846027),\n    # Population density\n    # min, 99.9 percentile\n    'population': (0., 2534.06298828125, 25.531384, 154.72331),\n    # We don't want to normalize the FireMasks.\n    # 1 indicates fire, 0 no fire, -1 unlabeled data\n    'PrevFireMask': (-1., 1., 0., 1.),\n    'FireMask': (-1., 1., 0., 1.)\n}","metadata":{"id":"GTTV3tjjCcdn","execution":{"iopub.status.busy":"2024-04-19T20:47:28.280063Z","iopub.execute_input":"2024-04-19T20:47:28.280688Z","iopub.status.idle":"2024-04-19T20:47:28.291788Z","shell.execute_reply.started":"2024-04-19T20:47:28.280649Z","shell.execute_reply":"2024-04-19T20:47:28.29086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following cell defines cropping functions for extracting regions of the desired size from the input data.","metadata":{}},{"cell_type":"code","source":"\"\"\"Library of common functions used in deep learning neural networks.\n\"\"\"\ndef random_crop_input_and_output_images(\n    input_img: tf.Tensor,\n    output_img: tf.Tensor,\n    sample_size: int,\n    num_in_channels: int,\n    num_out_channels: int,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Randomly axis-align crop input and output image tensors.\n\n    Args:\n        input_img: tensor with dimensions HWC.\n        output_img: tensor with dimensions HWC.\n        sample_size: side length (square) to crop to.\n        num_in_channels: number of channels in input_img.\n        num_out_channels: number of channels in output_img.\n    Returns:\n        input_img: tensor with dimensions HWC.\n        output_img: tensor with dimensions HWC.\n    \"\"\"\n    combined = tf.concat([input_img, output_img], axis=2)\n    combined = tf.image.random_crop(\n        combined,\n        [sample_size, sample_size, num_in_channels + num_out_channels])\n    input_img = combined[:, :, 0:num_in_channels]\n    output_img = combined[:, :, -num_out_channels:]\n    return input_img, output_img\n\n\ndef center_crop_input_and_output_images(\n    input_img: tf.Tensor,\n    output_img: tf.Tensor,\n    sample_size: int,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Center crops input and output image tensors.\n\n    Args:\n        input_img: tensor with dimensions HWC.\n        output_img: tensor with dimensions HWC.\n        sample_size: side length (square) to crop to.\n    Returns:\n        input_img: tensor with dimensions HWC.\n        output_img: tensor with dimensions HWC.\n    \"\"\"\n    central_fraction = sample_size / input_img.shape[0]\n    input_img = tf.image.central_crop(input_img, central_fraction)\n    output_img = tf.image.central_crop(output_img, central_fraction)\n    return input_img, output_img","metadata":{"id":"QqGYv21hD-2q","execution":{"iopub.status.busy":"2024-04-19T20:47:28.549463Z","iopub.execute_input":"2024-04-19T20:47:28.550157Z","iopub.status.idle":"2024-04-19T20:47:28.559142Z","shell.execute_reply.started":"2024-04-19T20:47:28.550117Z","shell.execute_reply":"2024-04-19T20:47:28.558466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following cell provides code for parsing the contents of the TensorFlow Record files. In addition to loading the data, it also offers functions for various preprocessing operations, such as clipping, rescaling, or normalizing the data.  ","metadata":{}},{"cell_type":"code","source":"\"\"\"Dataset reader for Earth Engine data.\"\"\"\n\ndef _get_base_key(key: Text) -> Text:\n    \"\"\"Extracts the base key from the provided key.\n\n    Earth Engine exports TFRecords containing each data variable with its\n    corresponding variable name. In the case of time sequences, the name of the\n    data variable is of the form 'variable_1', 'variable_2', ..., 'variable_n',\n    where 'variable' is the name of the variable, and n the number of elements\n    in the time sequence. Extracting the base key ensures that each step of the\n    time sequence goes through the same normalization steps.\n    The base key obeys the following naming pattern: '([a-zA-Z]+)'\n    For instance, for an input key 'variable_1', this function returns 'variable'.\n    For an input key 'variable', this function simply returns 'variable'.\n\n    Args:\n        key: Input key.\n\n    Returns:\n        The corresponding base key.\n\n    Raises:\n        ValueError when `key` does not match the expected pattern.\n    \"\"\"\n    match = re.match(r'([a-zA-Z]+)', key)\n    if match:\n        return match.group(1)\n    \n    raise ValueError(\n      'The provided key does not match the expected pattern: {}'.format(key))\n\n\ndef _clip_and_rescale(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n    \"\"\"Clips and rescales inputs with the stats corresponding to `key`.\n\n    Args:\n        inputs: Inputs to clip and rescale.\n        key: Key describing the inputs.\n\n    Returns:\n        Clipped and rescaled input.\n\n    Raises:\n        ValueError if there are no data statistics available for `key`.\n    \"\"\"\n    base_key = _get_base_key(key)\n    if base_key not in DATA_STATS:\n        raise ValueError(\n            'No data statistics available for the requested key: {}.'.format(key))\n    min_val, max_val, _, _ = DATA_STATS[base_key]\n    inputs = tf.clip_by_value(inputs, min_val, max_val)\n    return tf.math.divide_no_nan((inputs - min_val), (max_val - min_val))\n\n\ndef _clip_and_normalize(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n    \"\"\"Clips and normalizes inputs with the stats corresponding to `key`.\n\n    Args:\n        inputs: Inputs to clip and normalize.\n        key: Key describing the inputs.\n\n    Returns:\n        Clipped and normalized input.\n\n    Raises:\n        ValueError if there are no data statistics available for `key`.\n    \"\"\"\n    base_key = _get_base_key(key)\n    if base_key not in DATA_STATS:\n        raise ValueError(\n            'No data statistics available for the requested key: {}.'.format(key))\n    min_val, max_val, mean, std = DATA_STATS[base_key]\n    inputs = tf.clip_by_value(inputs, min_val, max_val)\n    inputs = inputs - mean\n    return tf.math.divide_no_nan(inputs, std)\n\ndef _get_features_dict(\n    sample_size: int,\n    features: List[Text],\n) -> Dict[Text, tf.io.FixedLenFeature]:\n    \"\"\"Creates a features dictionary for TensorFlow IO.\n\n    Args:\n        sample_size: Size of the input tiles (square).\n        features: List of feature names.\n\n    Returns:\n        A features dictionary for TensorFlow IO.\n    \"\"\"\n    sample_shape = [sample_size, sample_size]\n    features = set(features)\n    columns = [\n        tf.io.FixedLenFeature(shape=sample_shape, dtype=tf.float32)\n        for _ in features\n    ]\n    return dict(zip(features, columns))\n\n\ndef _parse_fn(\n    example_proto: tf.train.Example, data_size: int, sample_size: int,\n    num_in_channels: int, clip_and_normalize: bool,\n    clip_and_rescale: bool, random_crop: bool, center_crop: bool,\n) -> Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Reads a serialized example.\n\n    Args:\n        example_proto: A TensorFlow example protobuf.\n        data_size: Size of tiles (square) as read from input files.\n        sample_size: Size the tiles (square) when input into the model.\n        num_in_channels: Number of input channels.\n        clip_and_normalize: True if the data should be clipped and normalized.\n        clip_and_rescale: True if the data should be clipped and rescaled.\n        random_crop: True if the data should be randomly cropped.\n        center_crop: True if the data should be cropped in the center.\n\n    Returns:\n        (input_img, output_img) tuple of inputs and outputs to the ML model.\n    \"\"\"\n    if (random_crop and center_crop):\n        raise ValueError('Cannot have both random_crop and center_crop be True')\n    input_features, output_features = INPUT_FEATURES, OUTPUT_FEATURES\n    feature_names = input_features + output_features\n    features_dict = _get_features_dict(data_size, feature_names)\n    features = tf.io.parse_single_example(example_proto, features_dict)\n\n    if clip_and_normalize:\n        inputs_list = [\n            _clip_and_normalize(features.get(key), key) for key in input_features\n        ]\n    elif clip_and_rescale:\n        inputs_list = [\n            _clip_and_rescale(features.get(key), key) for key in input_features\n        ]\n    else:\n        inputs_list = [features.get(key) for key in input_features]\n  \n    inputs_stacked = tf.stack(inputs_list, axis=0)\n    input_img = tf.transpose(inputs_stacked, [1, 2, 0])\n\n    outputs_list = [features.get(key) for key in output_features]\n    assert outputs_list, 'outputs_list should not be empty'\n    outputs_stacked = tf.stack(outputs_list, axis=0)\n\n    outputs_stacked_shape = outputs_stacked.get_shape().as_list()\n    assert len(outputs_stacked.shape) == 3, ('outputs_stacked should be rank 3'\n                                            'but dimensions of outputs_stacked'\n                                            f' are {outputs_stacked_shape}')\n    output_img = tf.transpose(outputs_stacked, [1, 2, 0])\n\n    if random_crop:\n        input_img, output_img = random_crop_input_and_output_images(\n            input_img, output_img, sample_size, num_in_channels, 1)\n    if center_crop:\n        input_img, output_img = center_crop_input_and_output_images(\n            input_img, output_img, sample_size)\n    return input_img, output_img\n\n\ndef get_dataset(file_pattern: Text, data_size: int, sample_size: int,\n                batch_size: int, num_in_channels: int, compression_type: Text,\n                clip_and_normalize: bool, clip_and_rescale: bool,\n                random_crop: bool, center_crop: bool) -> tf.data.Dataset:\n    \"\"\"Gets the dataset from the file pattern.\n\n    Args:\n        file_pattern: Input file pattern.\n        data_size: Size of tiles (square) as read from input files.\n        sample_size: Size the tiles (square) when input into the model.\n        batch_size: Batch size.\n        num_in_channels: Number of input channels.\n        compression_type: Type of compression used for the input files.\n        clip_and_normalize: True if the data should be clipped and normalized, False\n          otherwise.\n        clip_and_rescale: True if the data should be clipped and rescaled, False\n          otherwise.\n        random_crop: True if the data should be randomly cropped.\n        center_crop: True if the data shoulde be cropped in the center.\n\n    Returns:\n        A TensorFlow dataset loaded from the input file pattern, with features\n        described in the constants, and with the shapes determined from the input\n        parameters to this function.\n    \"\"\"\n    if (clip_and_normalize and clip_and_rescale):\n        raise ValueError('Cannot have both normalize and rescale.')\n    dataset = tf.data.Dataset.list_files(file_pattern)\n    dataset = dataset.interleave(\n        lambda x: tf.data.TFRecordDataset(x, compression_type=compression_type),\n        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.map(\n        lambda x: _parse_fn(  # pylint: disable=g-long-lambda\n            x, data_size, sample_size, num_in_channels, clip_and_normalize,\n            clip_and_rescale, random_crop, center_crop),\n        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    return dataset","metadata":{"id":"VBvI9FuGEC09","execution":{"iopub.status.busy":"2024-04-19T20:47:28.849832Z","iopub.execute_input":"2024-04-19T20:47:28.850273Z","iopub.status.idle":"2024-04-19T20:47:28.879122Z","shell.execute_reply.started":"2024-04-19T20:47:28.85024Z","shell.execute_reply":"2024-04-19T20:47:28.87841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's load training, validation and test sets using function we define above","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128\n\ntrain_dataset = get_dataset('/kaggle/input/next-day-wildfire-spread/next_day_wildfire_spread_train*', \n    data_size=64, sample_size=32, batch_size=BATCH_SIZE,\n    num_in_channels=12, compression_type=None, clip_and_normalize=True,\n    clip_and_rescale=False, random_crop=True, center_crop=False)\n\nvalidation_dataset = get_dataset('/kaggle/input/next-day-wildfire-spread/next_day_wildfire_spread_eval*', \n    data_size=64, sample_size=32, batch_size=BATCH_SIZE,\n    num_in_channels=12, compression_type=None, clip_and_normalize=True,\n    clip_and_rescale=False, random_crop=True, center_crop=False)\n\ntest_dataset = get_dataset('/kaggle/input/next-day-wildfire-spread/next_day_wildfire_spread_test*',\n    data_size=64, sample_size=64, batch_size=BATCH_SIZE,\n    num_in_channels=12, compression_type=None, clip_and_normalize=True,\n    clip_and_rescale=False, random_crop=False, center_crop=False)","metadata":{"id":"X1jBBEinQbM0","execution":{"iopub.status.busy":"2024-04-19T20:47:29.144326Z","iopub.execute_input":"2024-04-19T20:47:29.144587Z","iopub.status.idle":"2024-04-19T20:47:30.039004Z","shell.execute_reply.started":"2024-04-19T20:47:29.144556Z","shell.execute_reply":"2024-04-19T20:47:30.038393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize data\nWe will check content of the dataset by plotting them","metadata":{"id":"bzCgCoxtgP-f"}},{"cell_type":"markdown","source":"Let's plot the data!\n\nFirst we define the names for each of our variables.","metadata":{}},{"cell_type":"code","source":"TITLES = [\n  'Elevation',\n  'Wind\\ndirection',\n  'Wind\\nvelocity',\n  'Min\\ntemp',\n  'Max\\ntemp',\n  'Humidity',\n  'Precip',\n  'Drought',\n  'Vegetation',\n  'Population\\ndensity',\n  'Energy\\nrelease\\ncomponent',\n  'Previous\\nfire\\nmask',\n  'Fire\\nmask'\n]","metadata":{"id":"bnG0_l_ChjUt","execution":{"iopub.status.busy":"2024-04-19T20:47:30.041193Z","iopub.execute_input":"2024-04-19T20:47:30.041579Z","iopub.status.idle":"2024-04-19T20:47:30.046221Z","shell.execute_reply.started":"2024-04-19T20:47:30.041533Z","shell.execute_reply":"2024-04-19T20:47:30.045426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define some helper variables for the plot. ","metadata":{}},{"cell_type":"code","source":"def plot_samples_from_dataset(dataset: tf.data.Dataset, n_rows: int):\n    \"\"\"\n    Plot 'n_rows' rows of samples from dataset.\n    \n    Args:\n        dataset (Dataset): Dataset from which to plot samples.\n        n_rows (int): Number of rows to plot.\n    \"\"\"\n    global TITLES\n    \n    # Get batch\n    inputs, labels = None, None\n    for elem in dataset:\n        inputs, labels = elem\n        break\n    \n    fig = plt.figure(figsize=(15,6.5))\n\n    # Variables for controllong the color map for the fire masks\n    CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n    BOUNDS = [-1, -0.1, 0.001, 1]\n    NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n    # Number of data variables\n    n_features = 12\n    for i in range(n_rows):\n        for j in range(n_features + 1):\n            plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n            if i == 0:\n                plt.title(TITLES[j], fontsize=13)\n            if j < n_features - 1:\n                plt.imshow(inputs[i, :, :, j], cmap='viridis')\n            if j == n_features - 1:\n                plt.imshow(inputs[i, :, :, -1], cmap=CMAP, norm=NORM)\n            if j == n_features:\n                plt.imshow(labels[i, :, :, 0], cmap=CMAP, norm=NORM) \n            plt.axis('off')\n    plt.tight_layout()\n    ","metadata":{"id":"sPtKQzQv71J_","outputId":"6694ad6e-0044-4fbc-b184-f615ac14a885","execution":{"iopub.status.busy":"2024-04-19T20:47:30.047297Z","iopub.execute_input":"2024-04-19T20:47:30.047897Z","iopub.status.idle":"2024-04-19T20:47:30.058578Z","shell.execute_reply.started":"2024-04-19T20:47:30.047857Z","shell.execute_reply":"2024-04-19T20:47:30.05789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_samples_from_dataset(train_dataset, 5)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:30.1755Z","iopub.execute_input":"2024-04-19T20:47:30.175741Z","iopub.status.idle":"2024-04-19T20:47:33.790105Z","shell.execute_reply.started":"2024-04-19T20:47:30.175714Z","shell.execute_reply":"2024-04-19T20:47:33.789337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building testing","metadata":{}},{"cell_type":"markdown","source":"## Metrics\nLet's define metric calculation functions","metadata":{}},{"cell_type":"code","source":"def IoU_metric(real_mask: tf.Tensor, predicted_mask: tf.Tensor) -> float:\n    \"\"\"\n    Calculation of intersection over union metric.\n    \n    Args:\n        real_mask (Tensor): Ground-truth mask\n        predicted_mask (Tensor): Mask predicted by model\n    Returns:\n        (float): IoU metric value\n    \"\"\"\n    real_mask = tf.where(real_mask < 0, 0, real_mask)\n    \n    intersection = np.logical_and(real_mask, predicted_mask)\n    union = np.logical_or(real_mask, predicted_mask)\n    \n    if np.sum(union) == 0:\n        return 1\n    return np.sum(intersection) / np.sum(union)\n\ndef recall_metric(real_mask: tf.Tensor, predicted_mask: tf.Tensor) -> float:\n    \"\"\"\n    Calculation of recall metric.\n    \n    Args:\n        real_mask (Tensor): Ground-truth mask\n        predicted_mask (Tensor): Mask predicted by model\n    Returns:\n        (float): recall metric value\n    \"\"\"\n    real_mask = tf.where(real_mask < 0, 0, real_mask)\n    \n    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n    actual_positives = np.sum(real_mask)\n    if actual_positives == 0:\n        return 1\n    \n    return true_positives / actual_positives\n\ndef precision_metric(real_mask: tf.Tensor, predicted_mask: tf.Tensor) -> float:\n    \"\"\"\n    Calculation of precision metric.\n    \n    Args:\n        real_mask (Tensor): Ground-truth mask\n        predicted_mask (Tensor): Mask predicted by model\n    Returns:\n        (float): precision metric value\n    \"\"\"\n    real_mask = tf.where(real_mask < 0, 0, real_mask)\n    \n    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n    predicted_positives = np.sum(predicted_mask)\n    if predicted_positives == 0:\n        return 1\n    \n    return true_positives / predicted_positives","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:33.791866Z","iopub.execute_input":"2024-04-19T20:47:33.79225Z","iopub.status.idle":"2024-04-19T20:47:33.805239Z","shell.execute_reply.started":"2024-04-19T20:47:33.792214Z","shell.execute_reply":"2024-04-19T20:47:33.804458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss functions","metadata":{}},{"cell_type":"code","source":"def dice_coef(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n    \"\"\"\n    Dice loss function calculator.\n    \n    Args:\n        y_true (Tensor): \n        y_pred (Tensor):\n    Returns:\n        (Tensor): Dice loss for each element of a batch.\n    \"\"\"\n    smooth = 1e-6\n    y_true_f = K.reshape(y_true, (BATCH_SIZE, -1))\n    y_pred_f = K.reshape(y_pred, (BATCH_SIZE, -1))\n    intersection = K.sum(y_true_f * y_pred_f, axis=1)\n    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f, axis=1) + K.sum(y_pred_f, axis=1) + smooth)\n\ndef weighted_bincrossentropy(true: tf.Tensor, pred: tf.Tensor, weight_zero: float = 0.01, weight_one: float = 1) -> float:\n    \"\"\"\n    Calculates weighted binary cross entropy. The weights are fixed.\n        \n    This can be useful for unbalanced catagories.\n    \n    Adjust the weights here depending on what is required.\n    \n    For example if there are 10x as many positive classes as negative classes,\n        if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives \n        will be penalize 10 times as much as false negatives.\n    \n    Args:\n        true (Tensor): Ground-truth values\n        pred (Tensor): Predited values\n        weight_zero (float): Weight of class 0 (no-fire)\n        weight_one (float): Weight of class 1 (fire)\n        \n    \"\"\"\n  \n    # calculate the binary cross entropy\n    bin_crossentropy = K.binary_crossentropy(true, pred)\n    \n    # apply the weights\n    weights = true * weight_one + (1. - true) * weight_zero\n    weighted_bin_crossentropy = weights * bin_crossentropy \n    \n    return K.mean(weighted_bin_crossentropy, axis=1)\n\ndef bce_dice_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n    \"\"\"\n    BCE loss function calculator.\n    \n    Args:\n        y_true (Tensor): \n        y_pred (Tensor):\n    Returns:\n        (Tensor): Mean BCE Dice loss over a batch.\n    \"\"\"\n    \n    y_true_f = K.reshape(y_true, (BATCH_SIZE, -1))\n    y_pred_f = K.reshape(y_pred, (BATCH_SIZE, -1))\n    return reduce_weighted_loss(weighted_bincrossentropy(y_true_f, y_pred_f) + dice_coef(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:33.806564Z","iopub.execute_input":"2024-04-19T20:47:33.80715Z","iopub.status.idle":"2024-04-19T20:47:33.821003Z","shell.execute_reply.started":"2024-04-19T20:47:33.807116Z","shell.execute_reply":"2024-04-19T20:47:33.82025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation loop\nLet's define evaluation process over specified dataset","metadata":{}},{"cell_type":"code","source":"def evaluate_model(prediction_function: Callable[[tf.Tensor], tf.Tensor],\n                   eval_dataset: tf.data.Dataset) -> Tuple[float, float, float, float]:\n    \"\"\"\n    Loads dataset according to file pattern and evaluates model's predictions on it.\n    \n    Parameters:\n        model (Callable[[tf.Tensor], tf.Tensor]): Function for model inference.\n        eval_dataset (tf.dataDataset): Dataset for evaluation.\n    \n    Returns:\n        Tuple[float, float, float, float]: IoU score, recall score, precision score and mean loss.\n    \"\"\"\n    IoU_measures = []\n    recall_measures = []\n    precision_measures = []\n    losses = []\n    \n    for inputs, labels in tqdm(eval_dataset):\n        # Prediction shape (N, W, H)\n        predictions = prediction_function(inputs)\n        for i in range(inputs.shape[0]):\n            IoU_measures.append(IoU_metric(labels[i, :, :,  0], predictions[i, :, :]))\n            recall_measures.append(recall_metric(labels[i, :, :,  0], predictions[i, :, :]))\n            precision_measures.append(precision_metric(labels[i, :, :,  0], predictions[i, :, :]))\n        labels_cleared = tf.where(labels < 0, 0, labels)\n        losses.append(bce_dice_loss(labels_cleared, tf.expand_dims(tf.cast(predictions, tf.float32), axis=-1)))\n            \n    mean_IoU = np.mean(IoU_measures)\n    mean_recall = np.mean(recall_measures)\n    mean_precision = np.mean(precision_measures)\n    mean_loss = np.mean(losses)\n    return mean_IoU, mean_recall, mean_precision, mean_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:33.822559Z","iopub.execute_input":"2024-04-19T20:47:33.822774Z","iopub.status.idle":"2024-04-19T20:47:33.836667Z","shell.execute_reply.started":"2024-04-19T20:47:33.822748Z","shell.execute_reply":"2024-04-19T20:47:33.836024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling technique\nDescription of technique","metadata":{}},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/tensorflow/examples.git","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:33.837619Z","iopub.execute_input":"2024-04-19T20:47:33.837824Z","iopub.status.idle":"2024-04-19T20:47:46.398153Z","shell.execute_reply.started":"2024-04-19T20:47:33.837799Z","shell.execute_reply":"2024-04-19T20:47:46.397382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow_examples.models.pix2pix import pix2pix\n\ndef build_CNN_AE_model() -> Model:\n    \"\"\"\n    Create CNN auto encode model.\n    \n    Returns:\n        (Model): Keras model.\n    \"\"\"\n    base_model = tf.keras.applications.MobileNetV2(input_shape=[32, 32, 12], include_top=False, weights=None)\n\n    # Use the activations of these layers\n    layer_names = [\n        'block_1_expand_relu',   # 32x32\n        'block_3_expand_relu',   # 16x16\n        'block_6_expand_relu',   # 8x8\n        'block_13_expand_relu',  # 4x4\n        'block_16_project',      # 2x2\n    ]\n    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n\n    # Create the feature extraction model\n    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n\n    down_stack.trainable = True\n\n    up_stack = [\n        pix2pix.upsample(512, 3),  # 2x2 -> 4x4\n        pix2pix.upsample(256, 3),  # 4x4 -> 8x8\n        pix2pix.upsample(128, 3),  # 8x8 -> 16x16\n        pix2pix.upsample(64, 3),   # 16x16 -> 32x32\n    ]\n\n    inputs = tf.keras.layers.Input(shape=[32, 32, 12])\n\n    # Downsampling through the model\n    skips = down_stack(inputs)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        concat = tf.keras.layers.Concatenate()\n        x = concat([x, skip])\n\n    # This is the last layer of the model\n    last = tf.keras.layers.Conv2DTranspose(\n        filters=1, kernel_size=3, strides=2,\n    padding='same')  #64x64 -> 128x128\n\n    x = last(x)\n    outputs = Conv2D(1, 1, padding='same', activation='sigmoid')(x)\n    return tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n# Create the segmentation model\nsegmentation_model = build_CNN_AE_model()\nsegmentation_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:46.399777Z","iopub.execute_input":"2024-04-19T20:47:46.400106Z","iopub.status.idle":"2024-04-19T20:47:48.1111Z","shell.execute_reply.started":"2024-04-19T20:47:46.400037Z","shell.execute_reply":"2024-04-19T20:47:48.110358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"def train_model(model: Model, train_dataset: tf.data.Dataset, epochs:int=10) -> Tuple[List[float], List[float]]:\n    \"\"\"\n    Trains a model using train dataset. (Save weights of model with best IoU)\n    \n    Args:\n        model (Model): Model to train.\n        train_dataset (Dataset): Training dataset.\n        epochs (int): Number of epochs\n    Returns:\n        Tuple[List[float], List[float]]: Train losses and Validation losses\n    \"\"\"\n    loss_fn = bce_dice_loss\n    optimizer = tf.keras.optimizers.Adam()\n    batch_losses = []\n    val_losses = []\n    best_IoU = 0.0\n    \n    for epoch in range(epochs):\n        losses = []\n        print(f'Epoch {epoch+1}/{epochs}')\n        # Iterate through the dataset\n        progress = tqdm(train_dataset)\n        for images, masks in progress:\n            with tf.GradientTape() as tape:\n                # Forward pass\n                predictions = model(images, training=True)\n                label = tf.where(masks < 0, 0, masks)\n                # Compute the loss\n                loss = loss_fn(label, predictions)\n                losses.append(loss.numpy())\n                progress.set_postfix({'batch_loss': loss.numpy()})\n            # Compute gradients\n            gradients = tape.gradient(loss, model.trainable_variables)\n            # Update the model's weights\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n        # Evaluate model\n        print(\"Evaluation...\")\n        IoU, recall, precision, val_loss = evaluate_model(lambda x: tf.where(model.predict(x) > 0.5, 1, 0)[:,:,:,0], validation_dataset)\n        print(\"Validation set metrics:\")\n        print(f\"Mean IoU: {IoU}\\nMean precision: {precision}\\nMean recall: {recall}\\nValidation loss: {val_loss}\\n\")\n        # Save best model\n        if IoU > best_IoU:\n            best_IoU = IoU\n            model.save_weights(\"best.h5\")\n        \n        # Print the loss for monitoring\n        print(f'Epoch: {epoch}, Train loss: {np.mean(losses)}')\n        batch_losses.append(np.mean(losses))\n        val_losses.append(val_loss)\n    \n    print(f\"Best model IoU: {best_IoU}\")\n    return batch_losses, val_losses\n\n# Set reproducability\ntf.random.set_seed(1337)\n\nsegmentation_model = build_CNN_AE_model()\ntrain_losses, val_losses = train_model(segmentation_model, train_dataset, epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:47:48.113374Z","iopub.execute_input":"2024-04-19T20:47:48.113952Z","iopub.status.idle":"2024-04-19T20:54:16.101074Z","shell.execute_reply.started":"2024-04-19T20:47:48.113907Z","shell.execute_reply":"2024-04-19T20:54:16.100348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot loss functions","metadata":{}},{"cell_type":"code","source":"def plot_train_and_val_losses(train_losses, val_losses):\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n    axs[0].plot(train_losses)\n    axs[0].set_title(\"train loss\")\n    \n    axs[1].plot(val_losses)\n    axs[1].set_title(\"validation loss\")\n    \n    plt.show()\n\n\nplot_train_and_val_losses(train_losses, val_losses)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:01:51.97239Z","iopub.execute_input":"2024-04-19T21:01:51.973168Z","iopub.status.idle":"2024-04-19T21:01:52.326079Z","shell.execute_reply.started":"2024-04-19T21:01:51.973126Z","shell.execute_reply":"2024-04-19T21:01:52.325333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"# Load best model\nsegmentation_model = build_CNN_AE_model()\nsegmentation_model.load_weights(\"best.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:01:58.621592Z","iopub.execute_input":"2024-04-19T21:01:58.621852Z","iopub.status.idle":"2024-04-19T21:02:00.165487Z","shell.execute_reply.started":"2024-04-19T21:01:58.621823Z","shell.execute_reply":"2024-04-19T21:02:00.164834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics on test set\nCalculating metrics on test set","metadata":{}},{"cell_type":"code","source":"def predict_on_full_image(x_batch: tf.Tensor) -> tf.Tensor:\n    \"\"\"\n    Do model inference of full 64x64 image.\n    \n    Args:\n        x_batch (tf.Tensor): Input batch with 64x64 images.\n    Returns:\n        (tf.Tensor): Prediction 64x64 image mask.\n    \"\"\"\n    global segmentation_model\n    b_size = x_batch.shape[0]\n    top_left = x_batch[:, :32, :32]\n    top_right = x_batch[:, :32, 32:]\n    bottom_left = x_batch[:, 32:, :32]\n    bottom_right = x_batch[:, 32:, 32:]\n\n    stacked_tensor = tf.stack([top_left, top_right, bottom_left, bottom_right], axis=1)\n    stacked_tensor = tf.reshape(stacked_tensor, (4*b_size, 32, 32, -1))\n    result_tensor = segmentation_model.predict(stacked_tensor)\n\n    reshaped_tensor = tf.reshape(result_tensor, (b_size, 2, 2, 32, 32, -1))\n    reconstructed_tensor = tf.concat([\n        tf.concat([reshaped_tensor[:, 0, 0], reshaped_tensor[:, 0, 1]], axis=2),\n        tf.concat([reshaped_tensor[:, 1, 0], reshaped_tensor[:, 1, 1]], axis=2)\n    ], axis=1)\n    return tf.where(reconstructed_tensor[:, :, :, 0] > 0.5, 1, 0)\n\nprint(\"Evaluation...\")\nprint(\"Test set metrics:\")\nIoU, recall, precision, val_loss = evaluate_model(predict_on_full_image, test_dataset)\nprint(f\"Mean IoU: {IoU}\\nMean precision: {precision}\\nMean recall: {recall}\\nTest loss: {val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:02:00.166935Z","iopub.execute_input":"2024-04-19T21:02:00.167188Z","iopub.status.idle":"2024-04-19T21:02:08.257751Z","shell.execute_reply.started":"2024-04-19T21:02:00.167157Z","shell.execute_reply":"2024-04-19T21:02:08.256975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparison with statistical model\nHow better is our model in comparison of prediction of only high frequency fire cells (>0.2 probability of being on fire)","metadata":{}},{"cell_type":"code","source":"class NaivePredictor:\n    \"\"\"\n    Naive predictor that predicts fire only if cell has chance being on fire more than 0.2\n    \"\"\"\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize model and create frequency matrix\n        \"\"\"\n        self.frequency_matrix = tf.zeros((32, 32), dtype=np.float32)\n    \n    def train(self, train_dataset: tf.data.Dataset) -> None:\n        \"\"\"\n        Train by calculating frequency for each cell.\n        \n        Args:\n            train_dataset (Dataset): Dataset to train on.\n        \"\"\"\n        for _, labels in tqdm(train_dataset):\n            label_batch = labels[:, :, :, 0]\n            label_batch = tf.where(label_batch < 0, 0, label_batch)\n            self.frequency_matrix = self.frequency_matrix + np.sum(label_batch, axis=0)\n        self.frequency_matrix = self.frequency_matrix / np.max(self.frequency_matrix)\n        self.frequency_matrix = tf.where(self.frequency_matrix > 0.2, 1, 0)\n    \n    def predict(self, X: tf.Tensor) -> tf.Tensor:\n        \"\"\"\n        Dummy predict function.\n        \n        Args:\n            train_dataset (Dataset): Dataset to train on.\n        Returns:\n            (Tensor): Predicted fire mask.\n        \"\"\"\n        return tf.tile(tf.expand_dims(self.frequency_matrix, axis=0), [X.shape[0],1,1])\n\nnaive_predictor = NaivePredictor()\nnaive_predictor.train(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:02:16.166759Z","iopub.execute_input":"2024-04-19T21:02:16.167569Z","iopub.status.idle":"2024-04-19T21:02:19.831093Z","shell.execute_reply.started":"2024-04-19T21:02:16.16752Z","shell.execute_reply":"2024-04-19T21:02:19.830239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IoU, recall, precision, val_loss = evaluate_model(naive_predictor.predict, test_dataset)\nprint(f\"Mean IoU: {IoU}\\nMean precision: {precision}\\nMean recall: {recall}\\nTest loss: {val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:31:06.397409Z","iopub.execute_input":"2024-04-12T22:31:06.397667Z","iopub.status.idle":"2024-04-12T22:31:10.05263Z","shell.execute_reply.started":"2024-04-12T22:31:06.397632Z","shell.execute_reply":"2024-04-12T22:31:10.051841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare trained model with Naive one: <br/>\n1. <font color=\"green\">IoU 23% better</font>\n2. <font color=\"green\">Precision 47% better</font>\n3. <font color=\"red\">Recall 50% worse</font>","metadata":{}},{"cell_type":"markdown","source":"# Inference on test set","metadata":{}},{"cell_type":"code","source":"def show_inference(n_rows: int, features: tf.Tensor, label: tf.Tensor, prediction_function: Callable[[tf.Tensor], tf.Tensor]) -> None:\n    \"\"\"\n    Show model inference through images.\n    \n    Args:\n        n_rows (int): Number of rows for subplots.\n        features (tf.Tensor): Input features.\n        label (tf.Tensor): True labels.\n        prediction_function (Callable[[tf.Tensor], tf.Tensor]): Function for model prediction.\n    \"\"\"\n    \n    # Variables for controllong the color map for the fire masks\n    CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n    BOUNDS = [-1, -0.1, 0.001, 1]\n    NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n    \n    fig = plt.figure(figsize=(15,n_rows*4))\n    \n    prediction = prediction_function(features)\n    for i in range(n_rows):\n        plt.subplot(n_rows, 3, i*3 + 1)\n        plt.title(\"Previous day fire\")\n        plt.imshow(features[i, :, :, -1], cmap=CMAP, norm=NORM)\n        plt.axis('off')\n        plt.subplot(n_rows, 3, i*3 + 2)\n        plt.title(\"True next day fire\")\n        plt.imshow(label[i, :, :, 0], cmap=CMAP, norm=NORM)\n        plt.axis('off')\n        plt.subplot(n_rows, 3, i*3 + 3)\n        plt.title(\"Predicted next day fire\")\n        plt.imshow(prediction[i, :, :])\n        plt.axis('off')    \n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:02:24.114209Z","iopub.execute_input":"2024-04-19T21:02:24.114509Z","iopub.status.idle":"2024-04-19T21:02:24.125395Z","shell.execute_reply.started":"2024-04-19T21:02:24.114475Z","shell.execute_reply":"2024-04-19T21:02:24.124475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features, labels = next(iter(test_dataset))\nshow_inference(5, features, labels, predict_on_full_image)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:03:48.107354Z","iopub.execute_input":"2024-04-19T21:03:48.107657Z","iopub.status.idle":"2024-04-19T21:03:49.558023Z","shell.execute_reply.started":"2024-04-19T21:03:48.107624Z","shell.execute_reply":"2024-04-19T21:03:49.557206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}